name: trend-site
on:
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download latest warehouse artifact
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: update-warehouse.yml
          workflow_conclusion: success
          name: warehouse
          search_artifacts: true
          path: artifacts

      - name: Restore warehouse
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data/warehouse/daily
          ZIP=$(find artifacts -maxdepth 2 -type f -name '*.zip' | head -n1 || true)
          if [ -n "${ZIP:-}" ]; then
            mkdir -p artifacts/unpacked
            unzip -q "$ZIP" -d artifacts/unpacked
          fi
          if [ -d artifacts/data/warehouse/daily ]; then
            rsync -av artifacts/data/warehouse/daily/ data/warehouse/daily/
            [ -f artifacts/data/warehouse/master.jsonl ] && cp -f artifacts/data/warehouse/master.jsonl data/warehouse/master.jsonl || true
          elif [ -d artifacts/warehouse/daily ]; then
            rsync -av artifacts/warehouse/daily/ data/warehouse/daily/
            [ -f artifacts/warehouse/master.jsonl ] && cp -f artifacts/warehouse/master.jsonl data/warehouse/master.jsonl || true
          elif [ -d artifacts/unpacked/data/warehouse/daily ]; then
            rsync -av artifacts/unpacked/data/warehouse/daily/ data/warehouse/daily/
            [ -f artifacts/unpacked/data/warehouse/master.jsonl ] && cp -f artifacts/unpacked/data/warehouse/master.jsonl data/warehouse/master.jsonl || true
          elif [ -d artifacts/unpacked/warehouse/daily ]; then
            rsync -av artifacts/unpacked/warehouse/daily/ data/warehouse/daily/
            [ -f artifacts/unpacked/warehouse/master.jsonl ] && cp -f artifacts/unpacked/warehouse/master.jsonl data/warehouse/master.jsonl || true
          elif [ -d artifacts/daily ]; then
            rsync -av artifacts/daily/ data/warehouse/daily/
            [ -f artifacts/master.jsonl ] && cp -f artifacts/master.jsonl data/warehouse/master.jsonl || true
          else
            echo "Warehouse dir not found in downloaded artifact"
            find artifacts -maxdepth 3 -print
            exit 23
          fi

      - name: Aggregate
        run: |
          set -euo pipefail
          python scripts/aggregate_from_warehouse.py \
            --warehouse data/warehouse/daily \
            --out run \
            --last-days 30 \
            --min-len 4 \
            --extra-stop config/extra_noise.txt

      - name: Make rising top
        shell: bash
        run: |
          set -euo pipefail
          cat > _mk_rising.py <<'PY'
import pandas as pd, pathlib
base = pathlib.Path("run")
outdir = base/"rising_csv"
outdir.mkdir(parents=True, exist_ok=True)
tok = pd.read_csv(base/"tokens_by_day.cleaned.csv")
top = tok.groupby("term")["count"].sum().sort_values(ascending=False).head(50).reset_index()
top.rename(columns={"count":"total"}, inplace=True)
(top).to_csv(outdir/"rising_terms_top.csv", index=False)
print("saved", outdir/"rising_terms_top.csv")
PY
          python _mk_rising.py

      - name: Build static site
        run: |
          set -euo pipefail
          python scripts/build_static_ui.py --run run --out site
          touch site/.nojekyll

      - name: Upload pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: site

  deploy:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      pages: write
      id-token: write
    steps:
      - uses: actions/deploy-pages@v4
