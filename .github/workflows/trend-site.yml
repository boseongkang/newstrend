name: trend-site
on:
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download latest warehouse artifact
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: update-warehouse.yml
          name: warehouse
          allow_forks: true
          path: artifacts

      - name: Restore warehouse
        run: |
          set -euo pipefail
          mkdir -p data/warehouse/daily
          ZIP=$(find artifacts -maxdepth 2 -type f -name '*.zip' | head -n1 || true)
          if [ -n "${ZIP:-}" ]; then
            mkdir -p artifacts/unpacked
            unzip -q "$ZIP" -d artifacts/unpacked
          fi
          if [ -d artifacts/data/warehouse/daily ]; then
            rsync -av --delete artifacts/data/warehouse/daily/ data/warehouse/daily/
            [ -f artifacts/data/warehouse/master.jsonl ] && cp -f artifacts/data/warehouse/master.jsonl data/warehouse/master.jsonl || true
          elif [ -d artifacts/warehouse/daily ]; then
            rsync -av --delete artifacts/warehouse/daily/ data/warehouse/daily/
            [ -f artifacts/warehouse/master.jsonl ] && cp -f artifacts/warehouse/master.jsonl data/warehouse/master.jsonl || true
          elif [ -d artifacts/unpacked/data/warehouse/daily ]; then
            rsync -av --delete artifacts/unpacked/data/warehouse/daily/ data/warehouse/daily/
            [ -f artifacts/unpacked/data/warehouse/master.jsonl ] && cp -f artifacts/unpacked/data/warehouse/master.jsonl data/warehouse/master.jsonl || true
          elif [ -d artifacts/unpacked/warehouse/daily ]; then
            rsync -av --delete artifacts/unpacked/warehouse/daily/ data/warehouse/daily/
            [ -f artifacts/unpacked/warehouse/master.jsonl ] && cp -f artifacts/unpacked/warehouse/master.jsonl data/warehouse/master.jsonl || true
          elif [ -d artifacts/daily ]; then
            rsync -av --delete artifacts/daily/ data/warehouse/daily/
            [ -f artifacts/master.jsonl ] && cp -f artifacts/master.jsonl data/warehouse/master.jsonl || true
          else
            echo "Warehouse layout not recognized"
            find artifacts -maxdepth 3 -print
            exit 23
          fi

      - name: Aggregate tokens
        run: |
          set -euo pipefail
          python scripts/aggregate_from_warehouse.py \
            --warehouse data/warehouse/daily \
            --out run \
            --last-days 30 \
            --min-len 4 \
            --extra-stop config/extra_noise.txt
          python - "$PWD/run" <<'PY'
import sys, pandas as pd, pathlib
outdir = pathlib.Path(sys.argv[1]) / "rising_csv"
outdir.mkdir(parents=True, exist_ok=True)
tok = pd.read_csv(pathlib.Path(sys.argv[1])/"tokens_by_day.cleaned.csv")
top = tok.groupby("term")["count"].sum().sort_values(ascending=False).head(50).reset_index()
top.to_csv(outdir/"rising_terms_top.csv", index=False)
PY

      - name: Build static site
        run: |
          set -euo pipefail
          python scripts/build_static_ui.py --run run --out site
          touch site/.nojekyll

      - name: Upload pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: site

  deploy:
    needs: build
    permissions:
      pages: write
      id-token: write
    runs-on: ubuntu-latest
    steps:
      - uses: actions/deploy-pages@v4
