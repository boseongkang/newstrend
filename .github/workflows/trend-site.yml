name: trend-site

on:
  workflow_dispatch:
  schedule:
    - cron: "15 7 * * *"

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: trend-site
  cancel-in-progress: true

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deploy.outputs.page_url }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install deps
        run: |
          python -m pip install -U pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install pandas numpy yfinance

      - name: Download latest warehouse artifact
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: update-warehouse.yml
          workflow_conclusion: success
          branch: main
          name: warehouse
          path: _wh
          if_no_artifact_found: fail

      - name: Restore warehouse
        run: |
          set -euo pipefail
          mkdir -p data/warehouse
          if [ -f _wh/artifact.tar ]; then
            tar -xf _wh/artifact.tar -C data/warehouse
          else
            cp -R _wh/* data/warehouse/ || true
          fi
          if [ -d data/warehouse/warehouse ]; then
            mv data/warehouse/warehouse/* data/warehouse/
            rmdir data/warehouse/warehouse || true
          fi
          test -f data/warehouse/master.jsonl
          test -d data/warehouse/daily

      - name: Aggregate and rising
        run: |
          set -euo pipefail
          python scripts/aggregate_from_warehouse.py \
            --warehouse data/warehouse/daily \
            --out run \
            --last-days 30 \
            --min-len 4 \
            --extra-stop config/extra_noise.txt
          python scripts/filter_tokens_csv.py \
            --in run/aggregate/tokens_by_day.csv \
            --stop-file config/extra_noise.txt \
            --min-len 4 \
            --out run/tokens_by_day.cleaned.csv
          START=$(python - <<'PY'
import pandas as pd
d=pd.read_csv("run/aggregate/articles_by_day.csv")["date"]
print(pd.to_datetime(d).min().date())
PY
)
          END=$(python - <<'PY'
import pandas as pd
d=pd.read_csv("run/aggregate/articles_by_day.csv")["date"]
print(pd.to_datetime(d).max().date())
PY
)
          python scripts/join_prices.py \
            --terms run/aggregate/tokens_by_day.csv \
            --map   config/ticker_aliases.json \
            --start "$START" --end "$END" \
            --out   run/prices_join

      - name: Build static site
        run: |
          set -euo pipefail
          python scripts/build_static_ui.py --run run --out site
          test -s site/index.html
          ls -l site/data

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: site

      - name: Deploy to GitHub Pages
        id: deploy
        uses: actions/deploy-pages@v4
