name: update-warehouse

on:
  schedule:
    - cron: "5,35 * * * *"
  workflow_dispatch: {}

permissions:
  contents: read
  actions: read

concurrency:
  group: update-warehouse
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with: { fetch-depth: 0 }

      - uses: actions/setup-python@v5
        with: { python-version: "3.12" }

      - name: Install
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install -e .

      - name: Download previous warehouse (optional)
        id: prev
        uses: dawidd6/action-download-artifact@v3
        with:
          repo: ${{ github.repository }}
          workflow: update-warehouse.yml
          workflow_conclusion: success
          branch: main
          name: warehouse
          search_artifacts: true
          if_no_artifact_found: warn
          path: prev_warehouse

      - name: Restore previous warehouse (if any)
        run: |
          set -euo pipefail
          if [ -d prev_warehouse ]; then
            mkdir -p data/warehouse data/metrics
            # zip이 풀려 내려오면 디렉토리 안쪽으로 한 단계 더 있음
            rsync -av prev_warehouse/ ./ || true
            rsync -av prev_warehouse/data/ ./ || true
          fi

      - name: Download latest live jsonl
        id: live_dl
        uses: dawidd6/action-download-artifact@v3
        with:
          repo: ${{ github.repository }}
          workflow: collect_continuous.yml
          workflow_conclusion: success
          branch: main
          name: live-jsonl
          search_artifacts: true
          if_no_artifact_found: warn
          path: live_artifacts

      - name: Restore live inputs
        id: restore_live
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data/live_newsapi/incoming
          cnt=0
          if [ -d live_artifacts ]; then
            find live_artifacts -type f -name '*.jsonl' -print0 | xargs -0 -I{} cp -v "{}" data/live_newsapi/incoming/ || true
            cnt=$(find data/live_newsapi/incoming -type f -name '*.jsonl' | wc -l | tr -d ' ')
          fi
          echo "count=${cnt}" >> "$GITHUB_OUTPUT"

      - name: Update corpus
        run: python scripts/update_corpus.py

      - name: Ensure warehouse exists (for first run)
        run: |
          set -euo pipefail
          if [ ! -f data/warehouse/master.jsonl ]; then
            echo "master.jsonl not found. Creating an empty skeleton so artifact is still produced."
            mkdir -p data/warehouse/daily data/metrics
            : > data/warehouse/master.jsonl
          fi

      - name: Upload warehouse
        if: hashFiles('data/warehouse/master.jsonl') != ''
        uses: actions/upload-artifact@v4
        with:
          name: warehouse
          path: |
            data/warehouse/master.jsonl
            data/warehouse/daily/*.jsonl
            data/metrics/**
          if-no-files-found: warn
          retention-days: 14
