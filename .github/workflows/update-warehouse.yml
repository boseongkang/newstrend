name: update-warehouse
on:
  workflow_dispatch:
  schedule:
    - cron: "23 * * * *"

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt
          pip install pandas numpy pyyaml || true

      - name: Download previous warehouse artifact
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: update-warehouse.yml
          name: warehouse
          path: prev_warehouse
          if_no_artifact_found: ignore

      - name: Restore previous warehouse
        run: |
          set -euo pipefail
          mkdir -p data/warehouse/daily
          SRC=prev_warehouse
          if [ -d prev_warehouse/warehouse ]; then SRC=prev_warehouse/warehouse; fi
          if [ -d "$SRC" ]; then rsync -a "$SRC"/ data/warehouse/; fi

      - name: Download latest live jsonl
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: collect_continuous.yml
          name: live-jsonl
          path: live_artifacts
          if_no_artifact_found: ignore

      - name: Restore live inputs
        run: |
          set -euo pipefail
          mkdir -p data/live_newsapi
          find live_artifacts -type f -name "*.jsonl" -exec mv {} data/live_newsapi/ \;
          ls -l data/live_newsapi || true

      - name: Update corpus
        run: |
          set -euo pipefail
          python scripts/update_corpus.py

      - name: Merge Live to Daily JSONL (Raw Data)
        shell: bash
        run: |
          python - <<'PY'
          import glob, os, re

          live_dir = "data/live_newsapi"
          warehouse_dir = "data/warehouse/daily"
          os.makedirs(warehouse_dir, exist_ok=True)

          files = sorted(glob.glob(os.path.join(live_dir, "*.jsonl")))
          
          for f in files:
              fname = os.path.basename(f)
              match = re.match(r"(\d{4}-\d{2}-\d{2})", fname)
              if match:
                  date_str = match.group(1)
                  dest = os.path.join(warehouse_dir, f"{date_str}.jsonl")
                  
                  with open(f, "r", encoding="utf-8") as infile:
                      content = infile.read()
                  
                  with open(dest, "a", encoding="utf-8") as outfile:
                      if content.strip():
                          outfile.write(content)
                          if not content.endswith("\n"):
                              outfile.write("\n")
                  print(f"Merged raw data: {fname} -> {dest}")
          PY

      - name: Extract terms to daily CSV
        run: |
          set -euo pipefail
          DT="$(date -u +%F)"
          python scripts/extract_terms.py \
            --inputs "data/live_newsapi/*.jsonl" "data/warehouse/daily/${DT}.jsonl" "data/warehouse/master.jsonl" \
            --outcsv "data/warehouse/daily/${DT}.csv" \
            --date "$DT" \
            --topk 800 --minlen 2 --mincount 2 \
            --max-ngram 3 \
            --stop configs/stopwords_en.txt \
            --alias configs/alias_en.yml


      - name: Upload warehouse artifact
        uses: actions/upload-artifact@v4
        with:
          name: warehouse
          path: |
            data/warehouse/master.jsonl
            data/warehouse/daily